<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Voice Activity Detection - Jellybook</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../../introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../../webrtc/index.html"><strong aria-hidden="true">2.</strong> WebRTC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../webrtc/congestion_control/cc.html"><strong aria-hidden="true">2.1.</strong> Congestion Control</a></li><li class="chapter-item expanded "><a href="../../webrtc/voice_activity_detection/vad.html" class="active"><strong aria-hidden="true">2.2.</strong> Voice Activity Detection</a></li></ol></li><li class="chapter-item expanded "><a href="../../rtsp/index.html"><strong aria-hidden="true">3.</strong> RTSP</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../rtsp/stream_setup.html"><strong aria-hidden="true">3.1.</strong> Receiving the stream</a></li><li class="chapter-item expanded "><a href="../../rtsp/stream_decoding.html"><strong aria-hidden="true">3.2.</strong> Decoding the stream</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../rtsp/conversions/rtsp_to_webrtc.html"><strong aria-hidden="true">3.2.1.</strong> RTSP to WebRTC</a></li><li class="chapter-item expanded "><a href="../../rtsp/conversions/rtsp_to_hls.html"><strong aria-hidden="true">3.2.2.</strong> RTSP to HLS</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="../../bugs/index.html"><strong aria-hidden="true">4.</strong> The Great Chapter of Bugs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../bugs/socket_buffer/socket_buffer.html"><strong aria-hidden="true">4.1.</strong> Packet loss in a local network</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Jellybook</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/jellyfish-dev/book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="voice-activity-detection"><a class="header" href="#voice-activity-detection">Voice Activity Detection</a></h1>
<p><em>It's just thresholding with extra steps</em></p>
<hr />
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of contents</a></h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#what-does-the-webrtc-protocol-provide">What does the WebRTC protocol provide?</a>
<ul>
<li><a href="#audio-level-header-extension">Audio Level Header extension</a></li>
<li><a href="#audio-level-processing">Audio Level processing</a></li>
</ul>
</li>
<li><a href="#the-algorithm">The algorithm</a></li>
<li><a href="#implementation-details">Implementation details</a></li>
<li><a href="#-tests--tests-tests--"><em>Tests, tests tests!</em></a>
<ul>
<li><a href="#unit-tests">Unit tests</a></li>
<li><a href="#manual-tests">Manual tests</a></li>
<li><a href="#performance">Performance</a></li>
</ul>
</li>
<li><a href="#conclusions">Conclusions</a>
<ul>
<li><a href="#where-it-pans-out">Where it pans out...</a></li>
<li><a href="#where-it-falls-short">...where it falls short...</a></li>
<li><a href="#and-what-can-be-added">...and what can be added.</a></li>
</ul>
</li>
</ol>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Voice Activity Detection (or <em>VAD</em> for short) is a technology that enables the automatic detection of speech activity in an audio signal. This is an essential tool for various applications such as speech recognition, speaker diarization, and voice communication systems.</p>
<p>In video conference applications VAD is implemented as a part of the audio processing pipeline. When a user speaks, the VAD algorithm detects the presence of speech activity by analyzing the noise levels of the audio signal.</p>
<p>For example, VAD can be used for showing an indicator that the user is speaking. In the picture below it can be seen in the upper left corner of the video tile.</p>
<p><img src="user_with_vad_indicator.png" alt="Vad indication" /></p>
<h2 id="what-does-the-webrtc-protocol-provide"><a class="header" href="#what-does-the-webrtc-protocol-provide">What does the WebRTC protocol provide?</a></h2>
<h3 id="audio-level-header-extension"><a class="header" href="#audio-level-header-extension">Audio Level Header extension</a></h3>
<p><a href="https://www.rfc-editor.org/rfc/rfc6464">RFC 6464</a> defines an Audio Level Header extension, which is very useful in the context of Voice Activity Detection, as it takes the implementation load of the SFU.</p>
<p>The Extension carries the information about the audio level in <code>-dBov</code> with values from 0 to 127.
Please pay attention to the minus, as it makes it so that the louder it gets, the lower the value becomes.
The fact that values are negative is a consequence of a definition of the <code>dBov</code> unit.</p>
<blockquote>
<p><strong>What is <code>dBov</code></strong></p>
<p><code>dBov</code> is defined as the level in <a href="https://en.wikipedia.org/wiki/Decibel">decibels</a> relative to the overload point of the system.
In this context, an overload point is the highest-intensity signal encodable by the payload format.
In simpler terms, the overload point is the loudest possible sound that can be encoded into the codec.</p>
</blockquote>
<p><a href="https://www.rfc-editor.org/rfc/rfc6464">RFC 6464</a> also defines an optional flag bit &quot;V&quot;.
When the use of it is negotiated, it indicates whether the encoder believes the audio packet contains voice activity.</p>
<p>Hopefully, you now have some understanding of the value in the <code>level</code> field, and we can jump right into the algorithm.
Don't worry, it's not difficult at all.</p>
<h3 id="audio-level-processing"><a class="header" href="#audio-level-processing">Audio Level processing</a></h3>
<p>You could use the flag bit &quot;V&quot; if available, but we don't recommend using it for the production environment for 2 reasons:</p>
<ol>
<li>It is optional, so you cannot be sure it will always be there.</li>
<li>Implementation isn't standardized, meaning you can have inconsistent behavior depending on the sender.</li>
</ol>
<p>So it's time to implement a different approach...</p>
<h2 id="the-algorithm"><a class="header" href="#the-algorithm">The algorithm</a></h2>
<p>First, let's define the inputs and outputs of our function that would perform VAD. The function takes audio noise levels and the noise threshold value as inputs. It returns information on whether the given audio levels indicate if the person is speaking based on the given threshold.</p>
<p><img src="vad_func.png" alt="vad_func" /></p>
<h3 id="the-main-idea"><a class="header" href="#the-main-idea">The main idea</a></h3>
<p>The main idea and many of the intricacies of the algorithm are provided in the original paper (that is <a href="https://israelcohen.com/wp-content/uploads/2018/05/IEEEI2012_Volfin.pdf"><em>Dominant Speaker Identification for Multipoint Videoconferencing</em> </a> by Ilana Volfin and Israel Cohen). The following implementation was inspired by it.</p>
<p>Basically, we take the input levels and group them into three layers of intervals: <em>immediates</em>, <em>mediums</em> and <em>longs</em>. Intervals contain a finite number of subunits (longs contain mediums, mediums contain immediates and immediates contain level). The intervals are then thresholded and labeled as <em>active</em> or <em>inactive</em>. Based on the number of active intervals, an <em>activity score</em> is computed for each kind of interval.</p>
<h3 id="in-a-little-more-detail"><a class="header" href="#in-a-little-more-detail">In a little more detail</a></h3>
<p><strong>The intervals</strong></p>
<p>There are three types of intervals:</p>
<ul>
<li><em>immediates</em> - smallest possible interval</li>
<li><em>mediums</em> - a sample that is about as long as a word</li>
<li><em>longs</em> - a sample that is about as long as a sentence</li>
</ul>
<p>There are also internal parameters of the algorithm like:</p>
<ul>
<li><code>@n1, @n2, @n3</code> - how many of the smaller intervals are in one bigger interval
<ul>
<li><code>@n1</code> - levels in one immediate</li>
<li><code>@n2</code> - immediates in one medium</li>
<li><code>@n3</code> - mediums in one long</li>
</ul>
</li>
<li><code>@mediums_subunit_threshold</code> - how many active immediates the medium interval should consist of to be counted as active</li>
<li><code>@long_subunit_threshold</code> - as above, but given the mediums and a long interval</li>
</ul>
<p>To compute them we take the input levels.</p>
<p><img src="levels.png" alt="levels" /></p>
<p>Then we combine them into immediates. Immediates are counted as active or inactive based on the threshold provided.</p>
<p><img src="immediates.png" alt="immediates" /></p>
<p>The numbers indicate the number of levels that are above the threshold. Since <code>@n1</code> is equal to one, immediates only have values 0 or 1.</p>
<p>After that, the mediums are computed in a similar fashion.</p>
<p><img src="mediums.png" alt="mediums" /></p>
<p>The red color indicates an inactive unit, whereas green symbolizes an active one. The numbers on mediums indicate counted active subunits of the lower tier.</p>
<p>Then the longs are counted.</p>
<p><img src="longs.png" alt="longs" /></p>
<p>And the interval computations are done!</p>
<p><em>Additional note</em></p>
<p>Typically, there is only one long interval. This means that the maximum number of levels needed can be simply counted by multiplying <code>@n1</code>, <code>@n2</code> and <code>@n3</code> and therefore:</p>
<ol>
<li>The algorithm takes a constant number of audio levels.</li>
<li>If the number of audio levels is smaller, it returns <code>:silence</code>.</li>
</ol>
<p><strong>Activity score</strong></p>
<p>After computing the intervals, we take the most recent one from all 3 lengths and compute the activity score for each one.
The computed values are also thresholded with other internal parameters called <code>@immediate_score_threshold</code>, <code>@medium_score_threshold</code> and <code>@long_score_threshold</code>.
If all the activity scores are above their threshold, the function returns <code>:speech</code>, otherwise <code>:false</code>.</p>
<p><img src="activity_score.png" alt="activity_score" /></p>
<p>The activity score formula is taken directly from the paper. It is a loglikelihood of two probabilities: the probability of speech and the probability of silence. It is based on the number of active subunits in a unit. The details are provided in the aforementioned paper.</p>
<h2 id="implementation-details"><a class="header" href="#implementation-details">Implementation details</a></h2>
<p>The algorithm described above was implemented as part of <a href="https://github.com/jellyfish-dev"><code>Jellyfish</code></a>. The implementation also handles:</p>
<ul>
<li>updating the queue in which the audio levels are stored</li>
<li>rolling over if a late packet has been delivered</li>
<li>sending information if the VAD status has changed</li>
</ul>
<p>Those steps are essential for the VAD to work properly in video conference context, so please, remember that in your own implementation.</p>
<p><strong>Other useful information</strong>:</p>
<ol>
<li>WebRTC usually uses UDP under the hood, so packets will arrive out of order.
You probably don't want to get a jitter buffer involved, so make sure that your time window implementation can handle out-of-order and possibly even late packets.</li>
<li>Remember that you're dealing with <code>-dBov</code>. The absolute value for silence is <code>127</code>, and the loudest possible sound has a value of <code>0</code>.</li>
</ol>
<h2 id="tests-tests-tests"><a class="header" href="#tests-tests-tests"><em>Tests, tests, tests!</em></a></h2>
<h3 id="manual-tests"><a class="header" href="#manual-tests">Manual tests</a></h3>
<p>The process of choosing internal parameters of the algorithm was not a trivial task. To have a better understanding of the inner workings of the algorithm, the VAD implementation was added to <a href="https://github.com/membraneframework/membrane_videoroom">a video conference application</a> and checked in terms of the return value and the activity scores it had produced.</p>
<p>The experiment consisted of telling the lines from Hamlet in Polish:</p>
<p><em>Niech ryczy z bólu ranny łoś,</em> (0.5 - 2.5 s)<br>
<em>zwierz zdrów przebiega knieje</em> (3.5 - 5.75 s)</p>
<p><code>True</code> values are expected in the aforementioned time ranges.</p>
<p>Then the audio levels along with the threshold and the actual results were plotted with the results given below.</p>
<p><img src="level_per_packet.png" alt="levels" /></p>
<p>Not every packet with a level above the threshold has a <code>True</code> value. That is expected because we don't want the algorithm to always be active.</p>
<p>The activity scores were as follows:</p>
<p><img src="immediate_score_per_packet.png" alt="immediates" /></p>
<p><img src="medium_score_per_packet.png" alt="mediums" /></p>
<p><img src="long_score_per_packet.png" alt="longs" /></p>
<p>Small activity scores mean that the packets above the threshold quickly generate <code>:speech</code> as output, but don't stop immediately. It can be changed by changing the algorithm parameters if needed.</p>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<p>Some small performance tests were done in order to check if the algorithm implemented in <a href="https://github.com/jellyfish-dev"><code>Jellyfish</code></a> is well-optimized and can serve in the real-time communication environment.</p>
<p>The time of the whole process was usually around 60 μs, which means no significant overhead. The number of reductions (function calls) was around 210. This matches our needs.</p>
<h2 id="conclusions"><a class="header" href="#conclusions">Conclusions</a></h2>
<h3 id="where-it-pans-out"><a class="header" href="#where-it-pans-out">Where it pans out...</a></h3>
<p>The algorithm is better than a simple count of a running average or thresholding without any additions. It generates plausible results quickly and without significant overhead. In short, the algorithm does what is expected.</p>
<h3 id="where-it-falls-short"><a class="header" href="#where-it-falls-short">...where it falls short...</a></h3>
<p>As always, there can be room for improvement.</p>
<p>The number of parameters is big, especially for a simple algorithm like this. This makes it hard to parametrize well and may produce confusion for people that do not understand the algorithm that well.</p>
<p>The fixed threshold is not well suited for WebRTC and videoconferencing in general, mostly because of different user audio settings and unspecified Auto Gain Control (AGC) behavior.</p>
<h3 id="and-what-can-be-added"><a class="header" href="#and-what-can-be-added">...and what can be added</a></h3>
<p><strong>Dominant Speaker Detection</strong></p>
<p>In the context of video conferencing platforms such as Jitsi, VAD is an important feature that allows for more efficient use of network resources by suppressing audio transmission during periods of silence. This can significantly reduce the bandwidth requirements and improve the overall quality of communication.</p>
<p>Once speech is detected, the audio stream is transmitted to other participants in the conference. When speech stops, the VAD algorithm detects the silence and stops transmitting the audio, thus reducing the network bandwidth usage.</p>
<p>A Dominant Speaker Detection like this could also be implemented in Videoroom. The estimation could be obtained from the activity scores computed during the described algorithm.</p>
<p><strong>Additional UI features in Videoroom</strong></p>
<p>Google Meet, Jitsi and many more WebRTC have <em>an animation</em> of what looks as <em>continuous</em> value returned by VAD. The indicator of speech moves along in correlation with how loud a person speaks.</p>
<p>For this to be completed in Videoroom, the activity score would need to be better adjusted.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../webrtc/congestion_control/cc.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../rtsp/index.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../webrtc/congestion_control/cc.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../rtsp/index.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js"></script>
        <script src="../../mark.min.js"></script>
        <script src="../../searcher.js"></script>

        <script src="../../clipboard.min.js"></script>
        <script src="../../highlight.js"></script>
        <script src="../../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
